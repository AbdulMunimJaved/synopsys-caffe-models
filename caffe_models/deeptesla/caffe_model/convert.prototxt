layer {
  name: "Placeholder"
  type: "Input"
  top: "Placeholder"
  input_param {
    shape {
      dim: 1
      dim: 66
      dim: 200
      dim: 3
    }
  }
}
layer {
  name: "Conv2D_perm0"
  type: "Permute"
  bottom: "Placeholder"
  top: "Conv2D_perm0"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "Conv2D_nchw"
  type: "Convolution"
  bottom: "Conv2D_perm0"
  top: "Conv2D_nchw"
  convolution_param {
    num_output: 24
    bias_term: true
    group: 1
    kernel_h: 5
    kernel_w: 5
    stride_h: 2
    stride_w: 2
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "Conv2D"
  type: "Permute"
  bottom: "Conv2D_nchw"
  top: "Conv2D"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Relu"
  type: "ReLU"
  bottom: "Conv2D"
  top: "Relu"
}
layer {
  name: "Conv2D_1_perm0"
  type: "Permute"
  bottom: "Relu"
  top: "Conv2D_1_perm0"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "Conv2D_1_nchw"
  type: "Convolution"
  bottom: "Conv2D_1_perm0"
  top: "Conv2D_1_nchw"
  convolution_param {
    num_output: 36
    bias_term: true
    group: 1
    kernel_h: 5
    kernel_w: 5
    stride_h: 2
    stride_w: 2
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "Conv2D_1"
  type: "Permute"
  bottom: "Conv2D_1_nchw"
  top: "Conv2D_1"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Relu_1"
  type: "ReLU"
  bottom: "Conv2D_1"
  top: "Relu_1"
}
layer {
  name: "Conv2D_2_perm0"
  type: "Permute"
  bottom: "Relu_1"
  top: "Conv2D_2_perm0"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "Conv2D_2_nchw"
  type: "Convolution"
  bottom: "Conv2D_2_perm0"
  top: "Conv2D_2_nchw"
  convolution_param {
    num_output: 48
    bias_term: true
    group: 1
    kernel_h: 5
    kernel_w: 5
    stride_h: 2
    stride_w: 2
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "Conv2D_2"
  type: "Permute"
  bottom: "Conv2D_2_nchw"
  top: "Conv2D_2"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Relu_2"
  type: "ReLU"
  bottom: "Conv2D_2"
  top: "Relu_2"
}
layer {
  name: "Conv2D_3_perm0"
  type: "Permute"
  bottom: "Relu_2"
  top: "Conv2D_3_perm0"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "Conv2D_3_nchw"
  type: "Convolution"
  bottom: "Conv2D_3_perm0"
  top: "Conv2D_3_nchw"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "Conv2D_3"
  type: "Permute"
  bottom: "Conv2D_3_nchw"
  top: "Conv2D_3"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Relu_3"
  type: "ReLU"
  bottom: "Conv2D_3"
  top: "Relu_3"
}
layer {
  name: "Conv2D_4_perm0"
  type: "Permute"
  bottom: "Relu_3"
  top: "Conv2D_4_perm0"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "Conv2D_4_nchw"
  type: "Convolution"
  bottom: "Conv2D_4_perm0"
  top: "Conv2D_4_nchw"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "Conv2D_4"
  type: "Permute"
  bottom: "Conv2D_4_nchw"
  top: "Conv2D_4"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Relu_4"
  type: "ReLU"
  bottom: "Conv2D_4"
  top: "Relu_4"
}
layer {
  name: "Reshape"
  type: "Reshape"
  bottom: "Relu_4"
  top: "Reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 1152
    }
  }
}
layer {
  name: "MatMul"
  type: "InnerProduct"
  bottom: "Reshape"
  top: "MatMul"
  inner_product_param {
    num_output: 1164
    bias_term: false
    transpose: true
  }
}
layer {
  name: "add_5"
  type: "Bias"
  bottom: "MatMul"
  top: "add_5"
  bias_param {
    axis: -1
  }
}
layer {
  name: "Relu_5"
  type: "ReLU"
  bottom: "add_5"
  top: "Relu_5"
}
layer {
  name: "MatMul_1"
  type: "InnerProduct"
  bottom: "Relu_5"
  top: "MatMul_1"
  inner_product_param {
    num_output: 100
    bias_term: false
    transpose: true
  }
}
layer {
  name: "add_6"
  type: "Bias"
  bottom: "MatMul_1"
  top: "add_6"
  bias_param {
    axis: -1
  }
}
layer {
  name: "Relu_6"
  type: "ReLU"
  bottom: "add_6"
  top: "Relu_6"
}
layer {
  name: "MatMul_2"
  type: "InnerProduct"
  bottom: "Relu_6"
  top: "MatMul_2"
  inner_product_param {
    num_output: 50
    bias_term: false
    transpose: true
  }
}
layer {
  name: "add_7"
  type: "Bias"
  bottom: "MatMul_2"
  top: "add_7"
  bias_param {
    axis: -1
  }
}
layer {
  name: "Relu_7"
  type: "ReLU"
  bottom: "add_7"
  top: "Relu_7"
}
layer {
  name: "MatMul_3"
  type: "InnerProduct"
  bottom: "Relu_7"
  top: "MatMul_3"
  inner_product_param {
    num_output: 10
    bias_term: false
    transpose: true
  }
}
layer {
  name: "add_8"
  type: "Bias"
  bottom: "MatMul_3"
  top: "add_8"
  bias_param {
    axis: -1
  }
}
layer {
  name: "Relu_8"
  type: "ReLU"
  bottom: "add_8"
  top: "Relu_8"
}
layer {
  name: "MatMul_4"
  type: "InnerProduct"
  bottom: "Relu_8"
  top: "MatMul_4"
  inner_product_param {
    num_output: 1
    bias_term: false
    transpose: true
  }
}
layer {
  name: "add_9"
  type: "Bias"
  bottom: "MatMul_4"
  top: "add_9"
  bias_param {
    axis: -1
  }
}
layer {
  name: "Atan"
  type: "Atan"
  bottom: "add_9"
  top: "Atan"
}
layer {
  name: "output/y"
  type: "Parameter"
  top: "output/y"
}
layer {
  name: "output"
  type: "Eltwise"
  bottom: "Atan"
  bottom: "output/y"
  top: "output"
  eltwise_param {
    operation: PROD
  }
}
