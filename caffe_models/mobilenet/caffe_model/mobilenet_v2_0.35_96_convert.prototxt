layer {
  name: "input"
  type: "Input"
  top: "input"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 96
      dim: 96
    }
  }
}
layer {
  name: "MobilenetV2/Conv/Conv2D_nchw"
  type: "Convolution"
  bottom: "input"
  top: "MobilenetV2/Conv/Conv2D_nchw"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 1
    pad_t: 0
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/Conv/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/Conv/Conv2D_nchw"
  top: "MobilenetV2/Conv/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/Conv/Relu6"
  top: "MobilenetV2/expanded_conv/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 16
    bias_term: false
    group: 16
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 1
    pad_r: 1
    pad_t: 1
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv/project/Conv2D_nchw"
  convolution_param {
    num_output: 8
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_1/expand/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv/project/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_1/expand/Conv2D_nchw"
  convolution_param {
    num_output: 48
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_1/expand/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_1/expand/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_1/expand/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_1/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_1/expand/Relu6"
  top: "MobilenetV2/expanded_conv_1/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 48
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 1
    pad_t: 0
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv_1/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv_1/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv_1/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv_1/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv_1/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv_1/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_1/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_1/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv_1/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_1/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_1/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv_1/project/Conv2D_nchw"
  convolution_param {
    num_output: 8
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_2/expand/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_1/project/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_2/expand/Conv2D_nchw"
  convolution_param {
    num_output: 48
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_2/expand/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_2/expand/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_2/expand/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_2/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_2/expand/Relu6"
  top: "MobilenetV2/expanded_conv_2/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 48
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 1
    pad_r: 1
    pad_t: 1
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv_2/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv_2/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv_2/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv_2/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv_2/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv_2/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_2/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_2/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv_2/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_2/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_2/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv_2/project/Conv2D_nchw"
  convolution_param {
    num_output: 8
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_2/add"
  type: "Eltwise"
  bottom: "MobilenetV2/expanded_conv_2/project/Conv2D_nchw"
  bottom: "MobilenetV2/expanded_conv_1/project/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_2/add"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_3/expand/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_2/add"
  top: "MobilenetV2/expanded_conv_3/expand/Conv2D_nchw"
  convolution_param {
    num_output: 48
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_3/expand/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_3/expand/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_3/expand/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_3/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_3/expand/Relu6"
  top: "MobilenetV2/expanded_conv_3/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 48
    bias_term: false
    group: 48
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 1
    pad_t: 0
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv_3/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv_3/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv_3/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv_3/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv_3/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv_3/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_3/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_3/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv_3/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_3/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_3/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv_3/project/Conv2D_nchw"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_4/expand/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_3/project/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_4/expand/Conv2D_nchw"
  convolution_param {
    num_output: 96
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_4/expand/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_4/expand/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_4/expand/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_4/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_4/expand/Relu6"
  top: "MobilenetV2/expanded_conv_4/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 96
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 1
    pad_r: 1
    pad_t: 1
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv_4/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv_4/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv_4/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv_4/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv_4/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv_4/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_4/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_4/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv_4/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_4/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_4/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv_4/project/Conv2D_nchw"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_4/add"
  type: "Eltwise"
  bottom: "MobilenetV2/expanded_conv_4/project/Conv2D_nchw"
  bottom: "MobilenetV2/expanded_conv_3/project/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_4/add"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_5/expand/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_4/add"
  top: "MobilenetV2/expanded_conv_5/expand/Conv2D_nchw"
  convolution_param {
    num_output: 96
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_5/expand/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_5/expand/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_5/expand/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_5/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_5/expand/Relu6"
  top: "MobilenetV2/expanded_conv_5/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 96
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 1
    pad_r: 1
    pad_t: 1
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv_5/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv_5/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv_5/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv_5/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv_5/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv_5/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_5/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_5/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv_5/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_5/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_5/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv_5/project/Conv2D_nchw"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_5/add"
  type: "Eltwise"
  bottom: "MobilenetV2/expanded_conv_5/project/Conv2D_nchw"
  bottom: "MobilenetV2/expanded_conv_4/add"
  top: "MobilenetV2/expanded_conv_5/add"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_6/expand/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_5/add"
  top: "MobilenetV2/expanded_conv_6/expand/Conv2D_nchw"
  convolution_param {
    num_output: 96
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_6/expand/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_6/expand/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_6/expand/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_6/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_6/expand/Relu6"
  top: "MobilenetV2/expanded_conv_6/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 96
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 1
    pad_t: 0
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv_6/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv_6/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv_6/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv_6/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv_6/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv_6/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_6/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_6/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv_6/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_6/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_6/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv_6/project/Conv2D_nchw"
  convolution_param {
    num_output: 24
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_7/expand/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_6/project/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_7/expand/Conv2D_nchw"
  convolution_param {
    num_output: 144
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_7/expand/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_7/expand/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_7/expand/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_7/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_7/expand/Relu6"
  top: "MobilenetV2/expanded_conv_7/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 144
    bias_term: false
    group: 144
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 1
    pad_r: 1
    pad_t: 1
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv_7/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv_7/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv_7/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv_7/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv_7/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv_7/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_7/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_7/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv_7/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_7/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_7/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv_7/project/Conv2D_nchw"
  convolution_param {
    num_output: 24
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_7/add"
  type: "Eltwise"
  bottom: "MobilenetV2/expanded_conv_7/project/Conv2D_nchw"
  bottom: "MobilenetV2/expanded_conv_6/project/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_7/add"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_8/expand/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_7/add"
  top: "MobilenetV2/expanded_conv_8/expand/Conv2D_nchw"
  convolution_param {
    num_output: 144
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_8/expand/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_8/expand/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_8/expand/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_8/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_8/expand/Relu6"
  top: "MobilenetV2/expanded_conv_8/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 144
    bias_term: false
    group: 144
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 1
    pad_r: 1
    pad_t: 1
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv_8/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv_8/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv_8/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv_8/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv_8/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv_8/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_8/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_8/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv_8/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_8/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_8/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv_8/project/Conv2D_nchw"
  convolution_param {
    num_output: 24
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_8/add"
  type: "Eltwise"
  bottom: "MobilenetV2/expanded_conv_8/project/Conv2D_nchw"
  bottom: "MobilenetV2/expanded_conv_7/add"
  top: "MobilenetV2/expanded_conv_8/add"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_9/expand/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_8/add"
  top: "MobilenetV2/expanded_conv_9/expand/Conv2D_nchw"
  convolution_param {
    num_output: 144
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_9/expand/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_9/expand/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_9/expand/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_9/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_9/expand/Relu6"
  top: "MobilenetV2/expanded_conv_9/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 144
    bias_term: false
    group: 144
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 1
    pad_r: 1
    pad_t: 1
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv_9/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv_9/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv_9/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv_9/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv_9/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv_9/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_9/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_9/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv_9/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_9/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_9/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv_9/project/Conv2D_nchw"
  convolution_param {
    num_output: 24
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_9/add"
  type: "Eltwise"
  bottom: "MobilenetV2/expanded_conv_9/project/Conv2D_nchw"
  bottom: "MobilenetV2/expanded_conv_8/add"
  top: "MobilenetV2/expanded_conv_9/add"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_10/expand/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_9/add"
  top: "MobilenetV2/expanded_conv_10/expand/Conv2D_nchw"
  convolution_param {
    num_output: 144
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_10/expand/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_10/expand/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_10/expand/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_10/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_10/expand/Relu6"
  top: "MobilenetV2/expanded_conv_10/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 144
    bias_term: false
    group: 144
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 1
    pad_r: 1
    pad_t: 1
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv_10/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv_10/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv_10/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv_10/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv_10/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv_10/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_10/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_10/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv_10/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_10/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_10/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv_10/project/Conv2D_nchw"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_11/expand/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_10/project/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_11/expand/Conv2D_nchw"
  convolution_param {
    num_output: 192
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_11/expand/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_11/expand/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_11/expand/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_11/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_11/expand/Relu6"
  top: "MobilenetV2/expanded_conv_11/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 192
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 1
    pad_r: 1
    pad_t: 1
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv_11/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv_11/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv_11/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv_11/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv_11/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv_11/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_11/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_11/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv_11/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_11/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_11/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv_11/project/Conv2D_nchw"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_11/add"
  type: "Eltwise"
  bottom: "MobilenetV2/expanded_conv_11/project/Conv2D_nchw"
  bottom: "MobilenetV2/expanded_conv_10/project/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_11/add"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_12/expand/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_11/add"
  top: "MobilenetV2/expanded_conv_12/expand/Conv2D_nchw"
  convolution_param {
    num_output: 192
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_12/expand/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_12/expand/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_12/expand/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_12/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_12/expand/Relu6"
  top: "MobilenetV2/expanded_conv_12/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 192
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 1
    pad_r: 1
    pad_t: 1
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv_12/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv_12/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv_12/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv_12/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv_12/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv_12/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_12/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_12/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv_12/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_12/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_12/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv_12/project/Conv2D_nchw"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_12/add"
  type: "Eltwise"
  bottom: "MobilenetV2/expanded_conv_12/project/Conv2D_nchw"
  bottom: "MobilenetV2/expanded_conv_11/add"
  top: "MobilenetV2/expanded_conv_12/add"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_13/expand/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_12/add"
  top: "MobilenetV2/expanded_conv_13/expand/Conv2D_nchw"
  convolution_param {
    num_output: 192
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_13/expand/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_13/expand/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_13/expand/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_13/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_13/expand/Relu6"
  top: "MobilenetV2/expanded_conv_13/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 192
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 1
    pad_t: 0
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv_13/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv_13/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv_13/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv_13/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv_13/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv_13/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_13/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_13/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv_13/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_13/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_13/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv_13/project/Conv2D_nchw"
  convolution_param {
    num_output: 56
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_14/expand/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_13/project/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_14/expand/Conv2D_nchw"
  convolution_param {
    num_output: 336
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_14/expand/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_14/expand/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_14/expand/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_14/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_14/expand/Relu6"
  top: "MobilenetV2/expanded_conv_14/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 336
    bias_term: false
    group: 336
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 1
    pad_r: 1
    pad_t: 1
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv_14/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv_14/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv_14/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv_14/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv_14/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv_14/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_14/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_14/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv_14/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_14/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_14/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv_14/project/Conv2D_nchw"
  convolution_param {
    num_output: 56
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_14/add"
  type: "Eltwise"
  bottom: "MobilenetV2/expanded_conv_14/project/Conv2D_nchw"
  bottom: "MobilenetV2/expanded_conv_13/project/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_14/add"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_15/expand/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_14/add"
  top: "MobilenetV2/expanded_conv_15/expand/Conv2D_nchw"
  convolution_param {
    num_output: 336
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_15/expand/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_15/expand/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_15/expand/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_15/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_15/expand/Relu6"
  top: "MobilenetV2/expanded_conv_15/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 336
    bias_term: false
    group: 336
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 1
    pad_r: 1
    pad_t: 1
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv_15/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv_15/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv_15/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv_15/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv_15/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv_15/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_15/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_15/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv_15/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_15/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_15/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv_15/project/Conv2D_nchw"
  convolution_param {
    num_output: 56
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_15/add"
  type: "Eltwise"
  bottom: "MobilenetV2/expanded_conv_15/project/Conv2D_nchw"
  bottom: "MobilenetV2/expanded_conv_14/add"
  top: "MobilenetV2/expanded_conv_15/add"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_16/expand/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_15/add"
  top: "MobilenetV2/expanded_conv_16/expand/Conv2D_nchw"
  convolution_param {
    num_output: 336
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/expanded_conv_16/expand/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_16/expand/Conv2D_nchw"
  top: "MobilenetV2/expanded_conv_16/expand/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_16/depthwise/depthwise_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_16/expand/Relu6"
  top: "MobilenetV2/expanded_conv_16/depthwise/depthwise_nchw"
  convolution_param {
    num_output: 336
    bias_term: false
    group: 336
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 1
    pad_r: 1
    pad_t: 1
    pad_b: 1
  }
}
layer {
  name: "MobilenetV2/expanded_conv_16/depthwise/BatchNorm/FusedBatchNorm_nchw"
  type: "BatchNorm"
  bottom: "MobilenetV2/expanded_conv_16/depthwise/depthwise_nchw"
  top: "MobilenetV2/expanded_conv_16/depthwise/BatchNorm/FusedBatchNorm_nchw"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000474974513
  }
}
layer {
  name: "MobilenetV2/expanded_conv_16/depthwise/BatchNorm/FusedBatchNorm_scale"
  type: "Scale"
  bottom: "MobilenetV2/expanded_conv_16/depthwise/BatchNorm/FusedBatchNorm_nchw"
  top: "MobilenetV2/expanded_conv_16/depthwise/BatchNorm/FusedBatchNorm_scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_16/depthwise/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/expanded_conv_16/depthwise/BatchNorm/FusedBatchNorm_scale"
  top: "MobilenetV2/expanded_conv_16/depthwise/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/expanded_conv_16/project/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_16/depthwise/Relu6"
  top: "MobilenetV2/expanded_conv_16/project/Conv2D_nchw"
  convolution_param {
    num_output: 112
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/Conv_1/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/expanded_conv_16/project/Conv2D_nchw"
  top: "MobilenetV2/Conv_1/Conv2D_nchw"
  convolution_param {
    num_output: 1280
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/Conv_1/Relu6"
  type: "ReLU"
  bottom: "MobilenetV2/Conv_1/Conv2D_nchw"
  top: "MobilenetV2/Conv_1/Relu6"
  relu_param {
    relu6: true
  }
}
layer {
  name: "MobilenetV2/Logits/AvgPool_nchw"
  type: "Pooling"
  bottom: "MobilenetV2/Conv_1/Relu6"
  top: "MobilenetV2/Logits/AvgPool_nchw"
  pooling_param {
    pool: AVE_EXC_PAD
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    ceil_mode: false
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/Logits/Conv2d_1c_1x1/Conv2D_nchw"
  type: "Convolution"
  bottom: "MobilenetV2/Logits/AvgPool_nchw"
  top: "MobilenetV2/Logits/Conv2d_1c_1x1/Conv2D_nchw"
  convolution_param {
    num_output: 1001
    bias_term: true
    group: 1
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
    dilation: 1
    pad_l: 0
    pad_r: 0
    pad_t: 0
    pad_b: 0
  }
}
layer {
  name: "MobilenetV2/Logits/Conv2d_1c_1x1/BiasAdd/MobilenetV2/Logits/Squeeze_perm"
  type: "Permute"
  bottom: "MobilenetV2/Logits/Conv2d_1c_1x1/Conv2D_nchw"
  top: "MobilenetV2/Logits/Conv2d_1c_1x1/BiasAdd/MobilenetV2/Logits/Squeeze_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "MobilenetV2/Logits/Squeeze"
  type: "Squeeze"
  bottom: "MobilenetV2/Logits/Conv2d_1c_1x1/BiasAdd/MobilenetV2/Logits/Squeeze_perm"
  top: "MobilenetV2/Logits/Squeeze"
  squeeze_param {
    axis: 1
    axis: 2
  }
}
layer {
  name: "MobilenetV2/Predictions/Reshape"
  type: "Reshape"
  bottom: "MobilenetV2/Logits/Squeeze"
  top: "MobilenetV2/Predictions/Reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 1001
    }
  }
}
layer {
  name: "MobilenetV2/Predictions/Softmax"
  type: "Softmax"
  bottom: "MobilenetV2/Predictions/Reshape"
  top: "MobilenetV2/Predictions/Softmax"
  softmax_param {
    axis: -1
  }
}
layer {
  name: "MobilenetV2/Predictions/Reshape_1"
  type: "Reshape"
  bottom: "MobilenetV2/Predictions/Softmax"
  top: "MobilenetV2/Predictions/Reshape_1"
  reshape_param {
    shape {
      dim: 1
      dim: 1001
    }
  }
}
